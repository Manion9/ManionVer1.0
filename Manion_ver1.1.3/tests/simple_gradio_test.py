#!/usr/bin/env python3
"""Simple Gradio interface for handwriting recognition test"""

import gradio as gr
import os
import sys
from dotenv import load_dotenv

# Add the manimator module to path
sys.path.insert(0, os.path.abspath('.'))

from manimator.api.scene_description import process_handwriting_prompt

# Load environment variables
load_dotenv()

def process_handwriting_image(image_file):
    """Process uploaded handwriting image"""
    try:
        if not image_file:
            return "âŒ No file uploaded"
        
        # Read the uploaded file
        with open(image_file, "rb") as f:
            image_data = f.read()
        
        print(f"Processing image: {image_file}")
        print(f"Image size: {len(image_data)} bytes")
        
        # Process with our handwriting function
        result = process_handwriting_prompt(image_data)
        
        return f"âœ… Scene Description Generated:\n\n{result}"
        
    except Exception as e:
        return f"âŒ Error processing image: {str(e)}"

def check_api_keys():
    """Check if API keys are configured"""
    mathpix_id = os.getenv('MATHPIX_APP_ID')
    google_key = os.getenv('GOOGLE_VISION_API_KEY')
    openai_key = os.getenv('OPENAI_API_KEY')
    
    status = f"""ğŸ”‘ API Key Status:
    
Mathpix: {'âœ… Configured' if mathpix_id else 'âŒ Missing'}
Google Vision: {'âœ… Configured' if google_key else 'âŒ Missing'}
OpenAI: {'âœ… Configured' if openai_key and openai_key != 'sk-your-actual-openai-key-here' else 'âŒ Please set real API key'}

Ready for testing: {'âœ… Yes' if all([mathpix_id, google_key, openai_key and openai_key != 'sk-your-actual-openai-key-here']) else 'âŒ Configure missing keys'}
"""
    return status

# Create Gradio interface
with gr.Blocks(title="Manimator Handwriting Test") as demo:
    gr.Markdown("# ğŸ¬ Manimator ì†ê¸€ì”¨ ì¸ì‹ í…ŒìŠ¤íŠ¸")
    gr.Markdown("ì¸ìˆ˜ë¶„í•´ ì†ê¸€ì”¨ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì—¬ Scene Descriptionì„ ìƒì„±í•´ë³´ì„¸ìš”!")
    
    # API status
    with gr.Row():
        status_output = gr.Textbox(
            label="API ìƒíƒœ", 
            value=check_api_keys(),
            interactive=False,
            lines=8
        )
    
    # File upload and processing
    with gr.Row():
        with gr.Column():
            image_input = gr.File(
                label="ì†ê¸€ì”¨ ì´ë¯¸ì§€ ì—…ë¡œë“œ (JPG, PNG)", 
                file_types=[".jpg", ".jpeg", ".png"]
            )
            process_btn = gr.Button("ğŸ” Scene Description ìƒì„±", variant="primary")
        
        with gr.Column():
            result_output = gr.Textbox(
                label="ê²°ê³¼", 
                lines=20,
                placeholder="ì—¬ê¸°ì— ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤..."
            )
    
    # Button click handler
    process_btn.click(
        fn=process_handwriting_image,
        inputs=[image_input],
        outputs=[result_output]
    )
    
    gr.Markdown("""
    ### ğŸ“‹ ì‚¬ìš© ë°©ë²•:
    1. ì²¨ë¶€í•´ì£¼ì‹  ì¸ìˆ˜ë¶„í•´ ì†ê¸€ì”¨ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œ
    2. ìœ„ì˜ íŒŒì¼ ì—…ë¡œë“œ ë²„íŠ¼ìœ¼ë¡œ ì—…ë¡œë“œ
    3. "Scene Description ìƒì„±" ë²„íŠ¼ í´ë¦­
    4. ê²°ê³¼ í™•ì¸!
    
    ### âš ï¸ ì£¼ì˜ì‚¬í•­:
    - OpenAI API í‚¤ê°€ .env íŒŒì¼ì— ì œëŒ€ë¡œ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
    - ëª¨ë“  API í‚¤ê°€ "âœ… Configured"ë¡œ í‘œì‹œë˜ì–´ì•¼ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤
    """)

if __name__ == "__main__":
    print("ğŸš€ Starting Manimator Handwriting Test Interface...")
    print("ğŸ“± Web interface will open in your browser")
    print("ğŸ”‘ Make sure your OpenAI API key is set in .env file!")
    
    demo.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False,
        debug=True
    )